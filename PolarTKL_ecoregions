"""
1
"""

import geopandas as gpd
import pandas as pd
import os
from concurrent.futures import ThreadPoolExecutor

# æ–‡ä»¶è·¯å¾„
hydrolake_path = r'G:\ren\CBR\Circumpolar_Thermokarst_Landscapes\Circumpolar_Thermokarst_Lakes.shp'
ecoregion_path = r'G:\ren\CBR\Ecoregions\Polar_ecoregions.shp'

# è¾“å‡ºè·¯å¾„
output_dir = r'C:\Users\zyb\Desktop\Handling project\ren\Polarthermlake_batches'
remain_dir = os.path.join(output_dir, 'Polar_lake_remain')
os.makedirs(output_dir, exist_ok=True)
os.makedirs(remain_dir, exist_ok=True)

# è¯»å–æ•°æ®
gdf_lakes = gpd.read_file(hydrolake_path)
gdf_regions = gpd.read_file(ecoregion_path).to_crs(gdf_lakes.crs)

# åˆ†æ‰¹æ•°æ®
chunk_size = 1000
chunks = [(i, gdf_lakes.iloc[i:i+chunk_size].copy()) for i in range(0, len(gdf_lakes), chunk_size)]

def process_chunk(idx, chunk):
    print(f"ğŸ”§ æ­£åœ¨å¤„ç†ç¬¬ {idx+1}/{len(chunks)} æ‰¹...")

    # å®Œå…¨åŒ…å«
    within_join = gpd.sjoin(chunk, gdf_regions, how='left', predicate='within')
    within_matched = within_join[~within_join['BIOME_NAME'].isna()]
    within_ids = within_matched['ID'].unique()

    # ç›¸äº¤
    intersects_join = gpd.sjoin(chunk, gdf_regions, how='left', predicate='intersects')
    intersects_counts = intersects_join.groupby('ID').size()
    single_intersect_ids = intersects_counts[intersects_counts == 1].index

    # åˆå¹¶ä¿ç•™æ¹–æ³Š
    keep_ids = set(within_ids).union(set(single_intersect_ids))
    keep_lakes = chunk[chunk['ID'].isin(keep_ids)]

    # è¾“å‡º Excel
    joined_for_output = gpd.sjoin(keep_lakes, gdf_regions, how='left', predicate='intersects')
    excel_path = os.path.join(output_dir, f"lake_batch_{idx+1:05}.xlsx")
    joined_for_output[['ID', 'BIOME_NAME', 'LTKTA_ha']].drop_duplicates().to_excel(excel_path, index=False)

    # è¾“å‡º remain shapefile
    remain_chunk = chunk[~chunk['ID'].isin(keep_ids)]
    if not remain_chunk.empty:
        remain_gdf = gpd.GeoDataFrame(remain_chunk, geometry='geometry', crs=gdf_lakes.crs)
        remain_path = os.path.join(remain_dir, f"lake_batch_{idx+1:05}_remain.shp")
        remain_gdf.to_file(remain_path)

    print(f"âœ… ç¬¬ {idx+1} æ‰¹å®Œæˆã€‚")

# å¤šçº¿ç¨‹æ‰§è¡Œ
with ThreadPoolExecutor(max_workers=8) as executor:
    executor.map(lambda args: process_chunk(*args), chunks)

print("ğŸ‰ æ‰€æœ‰æ‰¹æ¬¡å¤„ç†å®Œæˆï¼")
"""
2
"""
"""
2
"""

import geopandas as gpd
import pandas as pd
import os
import math

# ========== è·¯å¾„è®¾ç½® ==========
hydrolake_path = r'C:\Users\zyb\Desktop\Handling project\ren\Polarthermlake_batches\Polar_lake_remain\remain.shp'
ecoregion_path = r'G:\ren\CBR\Ecoregions\Polar_ecoregions.shp'
output_dir = r'C:\Users\zyb\Desktop\Handling project\ren\Polarthermlake_batches2'

os.makedirs(output_dir, exist_ok=True)

# ========== è¯»å–æ•°æ® ==========
lakes_all = gpd.read_file(hydrolake_path)
ecoregions = gpd.read_file(ecoregion_path)

# ========== æŠ•å½±ç»Ÿä¸€ï¼ˆåŒ—ææŠ•å½±ï¼‰ ==========
target_crs = 'EPSG:3995'
lakes_all = lakes_all.to_crs(target_crs)
ecoregions = ecoregions.to_crs(target_crs)

# ========== æ£€æŸ¥ ID å­—æ®µ ==========
if 'ID' not in lakes_all.columns:
    raise ValueError("æ¹–æ³Šæ•°æ®ä¸­ç¼ºå°‘ 'Hylak_id' å­—æ®µ")

# ========== åˆ†æ‰¹å¤„ç† ==========
batch_size = 20
num_batches = math.ceil(len(lakes_all) / batch_size)

for i in range(num_batches):
    print(f"ğŸ”„ æ­£åœ¨å¤„ç†ç¬¬ {i + 1} æ‰¹ / å…± {num_batches} æ‰¹...")

    lakes_batch = lakes_all.iloc[i * batch_size:(i + 1) * batch_size].copy()

    # äº¤é›†è®¡ç®—
    intersections = gpd.overlay(lakes_batch, ecoregions, how='intersection')
    intersections['intersect_area_m2'] = intersections.geometry.area

    # æŒ‰æœ€å¤§äº¤é¢ç§¯é€‰æ‹©ç”Ÿæ€åŒº
    intersections = intersections.sort_values('intersect_area_m2', ascending=False).drop_duplicates('ID')

    # æå–ç”Ÿæ€åŒºå­—æ®µ
    ecoregion_cols = [col for col in intersections.columns if col not in lakes_batch.columns and col not in ['geometry', 'intersect_area_m2']]
    intersections_df = intersections[['ID', 'intersect_area_m2'] + ecoregion_cols]

    # åˆå¹¶å±æ€§
    lakes_batch_df = lakes_batch.drop(columns='geometry')
    matched = pd.merge(lakes_batch_df, intersections_df, on='ID', how='left')

    # æ‹†åˆ†åŒ¹é…å’ŒæœªåŒ¹é…
    matched_valid = matched[matched['intersect_area_m2'].notna()]
    unmatched_ids = matched[matched['intersect_area_m2'].isna()]['ID']
    unmatched_gdf = lakes_batch[lakes_batch['ID'].isin(unmatched_ids)]

    # è¾“å‡º Excel
    excel_out = os.path.join(output_dir, f'batch_{i + 1}_matched.xlsx')
    matched_valid.to_excel(excel_out, index=False)

    # è¾“å‡ºæœªåŒ¹é… Shapefile
    if not unmatched_gdf.empty:
        shp_out = os.path.join(output_dir, f'batch_{i + 1}_remain_unmatched.shp')
        unmatched_gdf.to_file(shp_out)

    print(f"âœ… æ‰¹æ¬¡ {i + 1} å¤„ç†å®Œæˆï¼ŒåŒ¹é…æ•°: {len(matched_valid)}ï¼ŒæœªåŒ¹é…æ•°: {len(unmatched_gdf)}")

print("ğŸ‰ æ‰€æœ‰æ‰¹æ¬¡å¤„ç†å®Œæˆï¼")
