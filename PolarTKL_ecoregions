"""
1
"""

import geopandas as gpd
import pandas as pd
import os
from concurrent.futures import ThreadPoolExecutor

# 文件路径
hydrolake_path = r'G:\ren\CBR\Circumpolar_Thermokarst_Landscapes\Circumpolar_Thermokarst_Lakes.shp'
ecoregion_path = r'G:\ren\CBR\Ecoregions\Polar_ecoregions.shp'

# 输出路径
output_dir = r'C:\Users\zyb\Desktop\Handling project\ren\Polarthermlake_batches'
remain_dir = os.path.join(output_dir, 'Polar_lake_remain')
os.makedirs(output_dir, exist_ok=True)
os.makedirs(remain_dir, exist_ok=True)

# 读取数据
gdf_lakes = gpd.read_file(hydrolake_path)
gdf_regions = gpd.read_file(ecoregion_path).to_crs(gdf_lakes.crs)

# 分批数据
chunk_size = 1000
chunks = [(i, gdf_lakes.iloc[i:i+chunk_size].copy()) for i in range(0, len(gdf_lakes), chunk_size)]

def process_chunk(idx, chunk):
    print(f"🔧 正在处理第 {idx+1}/{len(chunks)} 批...")

    # 完全包含
    within_join = gpd.sjoin(chunk, gdf_regions, how='left', predicate='within')
    within_matched = within_join[~within_join['BIOME_NAME'].isna()]
    within_ids = within_matched['ID'].unique()

    # 相交
    intersects_join = gpd.sjoin(chunk, gdf_regions, how='left', predicate='intersects')
    intersects_counts = intersects_join.groupby('ID').size()
    single_intersect_ids = intersects_counts[intersects_counts == 1].index

    # 合并保留湖泊
    keep_ids = set(within_ids).union(set(single_intersect_ids))
    keep_lakes = chunk[chunk['ID'].isin(keep_ids)]

    # 输出 Excel
    joined_for_output = gpd.sjoin(keep_lakes, gdf_regions, how='left', predicate='intersects')
    excel_path = os.path.join(output_dir, f"lake_batch_{idx+1:05}.xlsx")
    joined_for_output[['ID', 'BIOME_NAME', 'LTKTA_ha']].drop_duplicates().to_excel(excel_path, index=False)

    # 输出 remain shapefile
    remain_chunk = chunk[~chunk['ID'].isin(keep_ids)]
    if not remain_chunk.empty:
        remain_gdf = gpd.GeoDataFrame(remain_chunk, geometry='geometry', crs=gdf_lakes.crs)
        remain_path = os.path.join(remain_dir, f"lake_batch_{idx+1:05}_remain.shp")
        remain_gdf.to_file(remain_path)

    print(f"✅ 第 {idx+1} 批完成。")

# 多线程执行
with ThreadPoolExecutor(max_workers=8) as executor:
    executor.map(lambda args: process_chunk(*args), chunks)

print("🎉 所有批次处理完成！")
"""
2
"""
"""
2
"""

import geopandas as gpd
import pandas as pd
import os
import math

# ========== 路径设置 ==========
hydrolake_path = r'C:\Users\zyb\Desktop\Handling project\ren\Polarthermlake_batches\Polar_lake_remain\remain.shp'
ecoregion_path = r'G:\ren\CBR\Ecoregions\Polar_ecoregions.shp'
output_dir = r'C:\Users\zyb\Desktop\Handling project\ren\Polarthermlake_batches2'

os.makedirs(output_dir, exist_ok=True)

# ========== 读取数据 ==========
lakes_all = gpd.read_file(hydrolake_path)
ecoregions = gpd.read_file(ecoregion_path)

# ========== 投影统一（北极投影） ==========
target_crs = 'EPSG:3995'
lakes_all = lakes_all.to_crs(target_crs)
ecoregions = ecoregions.to_crs(target_crs)

# ========== 检查 ID 字段 ==========
if 'ID' not in lakes_all.columns:
    raise ValueError("湖泊数据中缺少 'Hylak_id' 字段")

# ========== 分批处理 ==========
batch_size = 20
num_batches = math.ceil(len(lakes_all) / batch_size)

for i in range(num_batches):
    print(f"🔄 正在处理第 {i + 1} 批 / 共 {num_batches} 批...")

    lakes_batch = lakes_all.iloc[i * batch_size:(i + 1) * batch_size].copy()

    # 交集计算
    intersections = gpd.overlay(lakes_batch, ecoregions, how='intersection')
    intersections['intersect_area_m2'] = intersections.geometry.area

    # 按最大交面积选择生态区
    intersections = intersections.sort_values('intersect_area_m2', ascending=False).drop_duplicates('ID')

    # 提取生态区字段
    ecoregion_cols = [col for col in intersections.columns if col not in lakes_batch.columns and col not in ['geometry', 'intersect_area_m2']]
    intersections_df = intersections[['ID', 'intersect_area_m2'] + ecoregion_cols]

    # 合并属性
    lakes_batch_df = lakes_batch.drop(columns='geometry')
    matched = pd.merge(lakes_batch_df, intersections_df, on='ID', how='left')

    # 拆分匹配和未匹配
    matched_valid = matched[matched['intersect_area_m2'].notna()]
    unmatched_ids = matched[matched['intersect_area_m2'].isna()]['ID']
    unmatched_gdf = lakes_batch[lakes_batch['ID'].isin(unmatched_ids)]

    # 输出 Excel
    excel_out = os.path.join(output_dir, f'batch_{i + 1}_matched.xlsx')
    matched_valid.to_excel(excel_out, index=False)

    # 输出未匹配 Shapefile
    if not unmatched_gdf.empty:
        shp_out = os.path.join(output_dir, f'batch_{i + 1}_remain_unmatched.shp')
        unmatched_gdf.to_file(shp_out)

    print(f"✅ 批次 {i + 1} 处理完成，匹配数: {len(matched_valid)}，未匹配数: {len(unmatched_gdf)}")

print("🎉 所有批次处理完成！")
