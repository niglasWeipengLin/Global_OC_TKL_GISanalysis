"""
1
"""
import geopandas as gpd
import pandas as pd
import os
from concurrent.futures import ThreadPoolExecutor

# ====================== è·¯å¾„ ======================
hydrolake_path = r'G:\ren\CBR\GLAKES\Glakes_in_polar\GlakesInPolar.shp'
ecoregion_path = r'G:\ren\CBR\Ecoregions\Polar_ecoregions.shp'

output_dir = r'G:\ren\æ¹–æ³Šç”Ÿæ€åŒºç»Ÿè®¡\PolarGlakesEcoregionMatch'
remain_dir = os.path.join(output_dir, 'Polar_lake_remain')
os.makedirs(output_dir, exist_ok=True)
os.makedirs(remain_dir, exist_ok=True)

# ====================== è¯»å–æ•°æ® ======================
gdf_lakes   = gpd.read_file(hydrolake_path)
gdf_regions = gpd.read_file(ecoregion_path).to_crs(gdf_lakes.crs)

# ====================== åˆ†æ‰¹ ======================
chunk_size = 10000
chunks = [(batch_num, gdf_lakes.iloc[i:i + chunk_size].copy())
          for batch_num, i in enumerate(range(0, len(gdf_lakes), chunk_size))]

# åªå¤„ç†ä»ç¬¬ 205 æ‰¹å¼€å§‹çš„æ‰¹æ¬¡
start_batch = 205
chunks_to_process = [ch for ch in chunks if ch[0] >= start_batch - 1]

def process_chunk(idx, chunk):
    print(f"ğŸ”§ æ­£åœ¨å¤„ç†ç¬¬ {idx + 1}/{len(chunks)} æ‰¹...")

    # å®Œå…¨åŒ…å«
    within_join = gpd.sjoin(chunk, gdf_regions, how='left', predicate='within')
    within_matched = within_join[~within_join['BIOME_NAME'].isna()]
    within_ids = within_matched['Lake_id'].unique()

    # ç›¸äº¤
    intersects_join = gpd.sjoin(chunk, gdf_regions, how='left', predicate='intersects')
    intersects_counts = intersects_join.groupby('Lake_id').size()
    single_intersect_ids = intersects_counts[intersects_counts == 1].index

    # åˆå¹¶ä¿ç•™æ¹–æ³Š
    keep_ids = set(within_ids).union(set(single_intersect_ids))
    keep_lakes = chunk[chunk['Lake_id'].isin(keep_ids)]

    # è¾“å‡º Excel
    joined_for_output = gpd.sjoin(keep_lakes, gdf_regions, how='left', predicate='intersects')
    excel_path = os.path.join(output_dir, f"lake_batch_{idx + 1:05}.xlsx")
    joined_for_output[['Lake_id', 'BIOME_NAME', 'Area_PW']].drop_duplicates().to_excel(excel_path, index=False)

    # è¾“å‡º remain shapefile
    remain_chunk = chunk[~chunk['Lake_id'].isin(keep_ids)]
    if not remain_chunk.empty:
        remain_gdf = gpd.GeoDataFrame(remain_chunk, geometry='geometry', crs=gdf_lakes.crs)
        remain_path = os.path.join(remain_dir, f"lake_batch_{idx + 1:05}_remain.shp")
        remain_gdf.to_file(remain_path)

    print(f"âœ… ç¬¬ {idx + 1} æ‰¹å®Œæˆã€‚")

# ====================== å¤šçº¿ç¨‹æ‰§è¡Œ ======================
with ThreadPoolExecutor(max_workers=8) as executor:
    executor.map(lambda args: process_chunk(*args), chunks_to_process)

print("ğŸ‰ æŒ‡å®šæ‰¹æ¬¡å…¨éƒ¨å¤„ç†å®Œæˆï¼")

"""
2
"""

import geopandas as gpd
import pandas as pd
import os
import math

# ========== è·¯å¾„è®¾ç½® ==========
hydrolake_path = r'G:\ren\æ¹–æ³Šç”Ÿæ€åŒºç»Ÿè®¡\PolarGlakesEcoregionMatch\Polar_lake_remain\remain1.shp'
ecoregion_path = r'G:\ren\CBR\Ecoregions\Polar_ecoregions.shp'
output_dir = r'G:\ren\æ¹–æ³Šç”Ÿæ€åŒºç»Ÿè®¡\PolarGlakesEcoregionMatch2'

os.makedirs(output_dir, exist_ok=True)

# ========== è¯»å–æ•°æ® ==========
lakes_all = gpd.read_file(hydrolake_path)
ecoregions = gpd.read_file(ecoregion_path)

# ========== æŠ•å½±ç»Ÿä¸€ï¼ˆåŒ—ææŠ•å½±ï¼‰ ==========
target_crs = 'EPSG:3995'
lakes_all = lakes_all.to_crs(target_crs)
ecoregions = ecoregions.to_crs(target_crs)



# ========== åˆ†æ‰¹å¤„ç† ==========
batch_size = 50
num_batches = math.ceil(len(lakes_all) / batch_size)

for i in range(num_batches):
    print(f"ğŸ”„ æ­£åœ¨å¤„ç†ç¬¬ {i + 1} æ‰¹ / å…± {num_batches} æ‰¹...")

    lakes_batch = lakes_all.iloc[i * batch_size:(i + 1) * batch_size].copy()

    # äº¤é›†è®¡ç®—
    intersections = gpd.overlay(lakes_batch, ecoregions, how='intersection')
    intersections['intersect_area_m2'] = intersections.geometry.area

    # æŒ‰æœ€å¤§äº¤é¢ç§¯é€‰æ‹©ç”Ÿæ€åŒº
    intersections = intersections.sort_values('intersect_area_m2', ascending=False).drop_duplicates('Lake_id')

    # æå–ç”Ÿæ€åŒºå­—æ®µ
    ecoregion_cols = [col for col in intersections.columns if col not in lakes_batch.columns and col not in ['geometry', 'intersect_area_m2']]
    intersections_df = intersections[['Lake_id', 'intersect_area_m2'] + ecoregion_cols]

    # åˆå¹¶å±æ€§
    lakes_batch_df = lakes_batch.drop(columns='geometry')
    matched = pd.merge(lakes_batch_df, intersections_df, on='Lake_id', how='left')

    # æ‹†åˆ†åŒ¹é…å’ŒæœªåŒ¹é…
    matched_valid = matched[matched['intersect_area_m2'].notna()]
    unmatched_ids = matched[matched['intersect_area_m2'].isna()]['Lake_id']
    unmatched_gdf = lakes_batch[lakes_batch['Lake_id'].isin(unmatched_ids)]

    # è¾“å‡º Excel
    excel_out = os.path.join(output_dir, f'batch_{i + 1}_matched.xlsx')
    matched_valid.to_excel(excel_out, index=False)

    # è¾“å‡ºæœªåŒ¹é… Shapefile
    if not unmatched_gdf.empty:
        shp_out = os.path.join(output_dir, f'batch_{i + 1}_remain_unmatched.shp')
        unmatched_gdf.to_file(shp_out)

    print(f"âœ… æ‰¹æ¬¡ {i + 1} å¤„ç†å®Œæˆï¼ŒåŒ¹é…æ•°: {len(matched_valid)}ï¼ŒæœªåŒ¹é…æ•°: {len(unmatched_gdf)}")

print("ğŸ‰ æ‰€æœ‰æ‰¹æ¬¡å¤„ç†å®Œæˆï¼")
